#!/usr/bin/env python3

import argparse
import codecs
import collections
import contextlib
import itertools
import os.path
import struct
import sys
import unicodedata


def main():
    parser = argparse.ArgumentParser()
    parser.set_defaults(func=help_command)
    parser.add_argument("file")
    subparsers = parser.add_subparsers(dest="command")

    def sub(name, func, **kwds):
        parser = subparsers.add_parser(name, **kwds)
        parser.set_defaults(func=func)
        return parser

    sub("help", func=help_command, help="Show help")
    sub("info", func=info_command, help="Show user info from save file")
    sub("check", func=check_command, help="Check validity of save file")
    sub("list", func=list_command, help="List file entries in save file")
    sub("move", func=move_command, help="Move file entry within save file")
    get = sub("get", func=get_command, help="Extract local file from save file")
    add = sub("add", func=add_command, help="Insert local file into save file")
    delete = sub("del", func=del_command, help="Delete file entry from save file")

    add.add_argument("path")
    get.add_argument("title")
    get.add_argument("-o", "--out")
    delete.add_argument("title")

    args = parser.parse_args()
    try:
        args.func(parser, args)
    except ToolError as e:
        print(f"{args.path}: {e}", file=sys.stderr)
        exit(1)


class ToolError(Exception):
    pass


class Addr(collections.namedtuple("Addr", "bank gb rom")):

    __slots__ = ()

    def __new__(cls, *, bank=None, gb=None, cram=None, rom=None):
        if gb is not None:
            assert cram is None
            assert rom is None
            assert 0xA000 <= gb <= 0xC000
            assert 0 <= bank < 4
        elif cram is not None:
            assert bank is None
            assert gb is None
            assert rom is None
            assert 0 <= cram <= 0x8000
            bank = cram >> 13
            gb = (cram & 0x1FFF) + 0xA000
        elif rom is not None:
            assert bank is None
            assert gb is None
            assert cram is None
        else:
            raise TypeError("invalid arguments")

        return super().__new__(cls, bank, gb, rom)

    @property
    def cram(self):
        return (self[0] << 13) + (self[1] - 0xA000)

    def adjusted(self):
        if self.gb == 0xC000:
            return self + 2
        return self

    def __str__(self):
        if self.rom is not None:
            return f"ROM:${self.rom:04x}"
        return f"${self.bank:02x}:${self.gb:04x}"

    def __add__(self, value):
        return type(self)(cram=self.cram + value)

    def __sub__(self, value):
        return type(self)(cram=self.cram - value)


KissMeta = collections.namedtuple("KissMeta", "profile index".split())
KissEntry = collections.namedtuple("KissEntry", "addr cart_id owner".split())
KissFile = collections.namedtuple(
    "KissFile", "body size flags cart_id owner title icon".split()
)


class KissChunk(collections.namedtuple("KissChunk", "type addr prev next")):

    __slots__ = ()

    @property
    def body(self):
        return self.addr + HEADER_SIZE

    @property
    def size(self):
        return self.next.cram - self.addr.cram - HEADER_SIZE


class KissError(Exception):
    pass


@contextlib.contextmanager
def open_kiss(args, mode):
    with open(args.file, mode) as f:
        rom_info = detect_rom(f)
        if rom_info is not None:
            yield None, rom_info, f
            return

        meta = detect_meta(f)
        if meta is not None:
            yield meta, None, f
            return

    raise Exception("file contains neither ROM data nor GBKiss data")


def read_struct(fmt, file):
    return struct.unpack(fmt, file.read(struct.calcsize(fmt)))


def write_struct(fmt, file, *args):
    file.write(struct.pack(fmt, *args))


CHUNK_FREE = ord("F")
CHUNK_REGULAR = ord("R")
CHUNK_INITIAL = ord("Z")
CHUNK_FILE = [CHUNK_REGULAR, CHUNK_INITIAL]
CHUNK_SPECIAL = ord("S")
CHUNK_VALID = [CHUNK_FREE, CHUNK_REGULAR, CHUNK_INITIAL, CHUNK_SPECIAL]

HEADER_SIZE = 6
INDEX_COUNT = 120
INDEX_SIZE = HEADER_SIZE + (INDEX_COUNT * 4)
PROFILE_SIZE = 128

ICON_SIZE_2BPP = 0xC0
ICON_SIZE_1BPP = 0x60
BUILTIN_ICONS = {
    0x00: "text",
    0x01: "auto",
    0x81: "auto",
    0x40: "auto",
    0x41: "auto",
    0x42: "auto",
    0x43: "auto",
    0x44: "auto",
    0x45: "auto",
    0xFF: "auto",
}


NINTENDO_LOGO = (
    b"\xCE\xED\x66\x66\xCC\x0D\x00\x0B\x03\x73\x00\x83\x00\x0C\x00\x0D"
    b"\x00\x08\x11\x1F\x88\x89\x00\x0E\xDC\xCC\x6E\xE6\xDD\xDD\xD9\x99"
    b"\xBB\xBB\x67\x63\x6E\x0E\xEC\xCC\xDD\xDC\x99\x9F\xBB\xB9\x33\x3E"
)
ROMS = {
    b"POKEBOM": [0x74003],
    b"GBKISS MINIGAME": [
        0x18007,
        0x19EDD,
        0x1B2AD,
        0x1C09A,
        0x1DE25,
        0x1F66C,
        0x20000,
        0x2160F,
        0x21E16,
        0x2407A,
        0x243E6,
        0x256FE,
        0x28000,
        0x29690,
        0x29F1A,
        0x2B2DF,
        0x2C07A,
        0x2DAC6,
        0x30000,
        0x30718,
        0x3404D,
        0x354AE,
        0x3807F,
        0x385DC,
        0x38BEB,
        0x391A8,
        0x39811,
        0x3C04F,
        0x3C482,
        0x3C4A1,
    ],
}


def detect_rom(rom):
    rom.seek(0x0104)
    if rom.read(len(NINTENDO_LOGO)) != NINTENDO_LOGO:
        return None
    return rom.read(16).rstrip(b"\0")


def detect_meta(sav):
    sav.seek(0)
    data = sav.read()
    if data[2] ^ data[3] != 0xFF:
        return None

    offset = 0
    magic = bytes([CHUNK_SPECIAL, CHUNK_SPECIAL ^ 0xFF])
    while offset < len(data):
        try:
            i = data.index(magic, offset)
        except ValueError:
            break
        if i > len(data) - (INDEX_SIZE + PROFILE_SIZE):
            break
        offset = i + 2

        index = read_chunk_header(sav, seek=Addr(cram=i))
        profile = read_chunk_header(sav, seek=Addr(cram=i + INDEX_SIZE))
        if (
            (profile.type == CHUNK_SPECIAL)
            and (index.next == profile.addr)
            and (profile.prev == index.addr)
            and (profile.next.gb == 0xC000)
        ):
            return KissMeta(profile, index)

    return None


def read_chunk_header(sav, *, seek):
    sav.seek(seek.cram)
    ctype, inv_ctype, prevc, nextc = read_struct("<BBHH", sav)
    assert (ctype ^ inv_ctype) == 0xFF, f"invalid chunk at {seek}"
    if prevc < 0x8000:
        prevc = Addr(rom=prevc)
    elif seek.gb == 0xA002:
        prevc = Addr(bank=seek.bank - 1, gb=prevc)
    else:
        prevc = Addr(bank=seek.bank, gb=prevc)
    nextc = Addr(bank=seek.bank, gb=nextc)
    return KissChunk(ctype, seek, prevc, nextc)


def read_index(sav, meta):
    sav.seek(meta.index.body.cram)
    entries = []
    for i in range(120):
        addr, cart_id, owner = read_struct("<HBB", sav)
        addr = Addr(cram=addr)
        entries.append(KissEntry(addr, cart_id, owner))
    return entries


def read_all_chunks(sav, meta):
    chunks = []
    for bank in range(0, meta.profile.addr.bank + 1):
        addr = Addr(bank=bank, gb=0xA002)
        while addr.gb != 0xC000:
            chunks.append(read_chunk_header(sav, seek=addr))
            addr = chunks[-1].next
    return chunks


def read_file_header(sav, *, seek):
    sav.seek(seek.cram)
    size, flags, cart_id, header_size, owner = read_struct("<HBBBB", sav)
    icon_size = {
        0x10: ICON_SIZE_1BPP,
        0x18: ICON_SIZE_2BPP,
    }.get(flags & 0x18, 0)
    title = sav.read(header_size - icon_size - 1).decode("gbkiss_string")
    icon = None
    if icon_size:
        icon = sav.read(icon_size)
    return KissFile(sav.tell(), size, flags, cart_id, owner, title, icon)


def help_command(parser, args):
    parser.print_help()


def check_command(parser, args):
    ok = True
    with open_kiss(args, "rb") as (meta, rom, sav):
        if rom is not None:
            raise ToolError("cannot check ROM file")

        files = {}
        for entry in read_index(sav, meta):
            if entry.addr.cram > 0 and entry.cart_id != 0xFF:
                files[entry.addr - HEADER_SIZE] = read_file_header(sav, seek=entry.addr)

        chunks = {c.addr: c for c in read_all_chunks(sav, meta)}
        for addr, chunk in chunks.items():
            if chunk != meta.profile:
                next = chunks[chunk.next.adjusted()]
                if next.prev != chunk.addr:
                    print(
                        f"Chunk {next.body} has bad back-reference"
                        f" to {next.prev}; expected {chunk.body}"
                    )
                    ok = False
            if chunk.type not in CHUNK_VALID:
                print(f"Invalid chunk type ${chunk.type:02x} at {addr}")
                ok = False

        file_chunks = {k: v for k, v in chunks.items() if v.type in CHUNK_FILE}
        for addr in frozenset(files) | frozenset(file_chunks):
            if addr not in chunks:
                print(f"Index references non-chunk {addr}")
                ok = False
            elif addr not in file_chunks:
                print(f"Index references non-file chunk {addr}")
                ok = False
            elif addr not in files:
                print(f"Index lacks reference to file chunk {addr}")
                ok = False
            else:
                chunk = chunks[addr]
                file = files[addr]
                calc_size = chunk.next.cram - chunk.body.cram
                if (calc_size < file.size) or (calc_size > file.size + 5):
                    print(
                        f"File chunk {addr} has bad size ${calc_size:04x};"
                        f" expected ${file.size:04x}"
                    )
                    ok = False

        special_chunks = {k: v for k, v in chunks.items() if v.type == CHUNK_SPECIAL}
        del special_chunks[meta.profile.addr]
        del special_chunks[meta.index.addr]
        for addr in special_chunks:
            print(f"Invalid special chunk {addr}")
            ok = False

        free_chunks = {k: v for k, v in chunks.items() if v.type == CHUNK_FREE}
        for addr, chunk in free_chunks.items():
            if chunk.next in free_chunks:
                print(f"Consecutive free chunks {addr} and {chunk.next}")
                ok = False

    if ok:
        print(f"Validated {len(files)} files in {len(chunks)} chunks")
    else:
        sys.exit(1)


def info_command(parser, args):
    with open_kiss(args, "rb") as (meta, rom, sav):
        if rom is not None:
            raise ToolError("cannot get user info from ROM file")

        sav.seek(meta.profile.body.cram)
        profile = sav.read(122)
        name = profile[64:74].decode("gbkiss_char").rstrip()
        number = profile[74:86].decode("gbkiss_char").rstrip()
        memo = [
            profile[86:98].decode("gbkiss_char").rstrip(),
            profile[98:110].decode("gbkiss_char").rstrip(),
            profile[110:122].decode("gbkiss_char").rstrip(),
        ]
        while memo and not memo[-1]:
            memo.pop()

        print(f"NAME: {name}")
        print(f"NUM:  {number}")
        print("MEMO: " + "\n      ".join(memo))


def list_command(parser, args):
    with open_kiss(args, "rb") as (meta, rom, sav):
        table = [("N", "TITLE", "ADDR", "SIZE", "MARK", "OWNER", "ICON")]

        if meta is not None:
            addrs = []
            for i, entry in enumerate(read_index(sav, meta)):
                if entry.addr.cram == 0:
                    continue
                elif entry.cart_id == 0xFF:
                    table.append((i, "KISS MAIL", "n/a", "n/a", "◎", "$01", "auto"))
                    continue
                else:
                    addrs.append((i, entry.addr))
        else:
            if rom not in ROMS:
                raise ToolError("ROM contains no GBKiss files")
            addrs = list(enumerate(ROMS[rom]))

        for i, addr in addrs:
            file = read_file_header(sav, seek=addr)
            icon_kind = BUILTIN_ICONS.get(file.owner, "")
            if file.icon:
                icon_kind = "%dbpp" % (len(file.icon) // 0x60)
            if file.cart_id == 0xFF:
                mark = "×"
            elif file.flags & 0x06 == 0x06:
                mark = "◇"
            elif file.flags & 0x06 == 0x04:
                mark = "○"
            else:
                mark = "△"
            owner = "$%02x" % file.owner
            table.append((i, file.title, addr, file.size, mark, owner, icon_kind))

        _columnify(table)


def get_command(parser, args):
    out_path = args.out
    if out_path is None:
        out_path = args.title + ".gbf"

    with open_kiss(args, "rb") as (meta, rom, sav):
        if meta is not None:
            addrs = []
            for i, entry in enumerate(read_index(sav, meta)):
                if (entry.addr.cram != 0) and (entry.cart_id != 0xFF):
                    addrs.append((i, entry.addr))
        else:
            if rom not in ROMS:
                raise ToolError("ROM contains no GBKiss files")
            addrs = list(enumerate(ROMS[rom]))

        for i, addr in addrs:
            file = read_file_header(sav, seek=addr)
            if (file.title == args.title) or (str(i) == args.title):
                break
        else:
            raise ToolError(f"file {args.title}: not found")

        sav.seek(addr.cram)
        data = sav.read(file.size)
        with open(out_path, "wb") as out:
            out.write(data)
        print(f"Wrote {file.size} bytes to {out_path}", file=sys.stderr)


def add_command(parser, args):
    with open(args.path, "rb") as f:
        data = f.read()
        file = read_file_header(f, seek=Addr(cram=0))

    diamond = (file.flags & 0x06) == 0x06
    if file.size != len(data):
        raise ToolError(
            f"declared file size ${file.size:04x} != observed ${len(data):04x}"
        )

    with open_kiss(args, "rb+") as (meta, rom, sav):
        if rom is not None:
            raise ToolError("cannot add file to ROM file")

        for i, entry in enumerate(read_index(sav, meta)):
            if entry.addr.cram == 0:
                index_loc = i
                break
        else:
            raise ToolError(f"no space in index")

        chunks = read_all_chunks(sav, meta)
        chunks = {c for c in chunks if c.type == CHUNK_FREE}
        chunks = {c for c in chunks if c.size >= file.size}
        if not chunks:
            raise ToolError(f"no space in CRAM")
        if diamond:
            chunks = {c for c in chunks if c.body.gb == 0xA008}
            if not chunks:
                raise ToolError(f"no valid diamond space in CRAM")
        chunk = max(chunks, key=lambda chunk: chunk.body)

        # Split chunk if large enough: if it has space for another header
        # even if there would be zero space remaining for a chunk body.
        # Even though that chunk would not itself be useful,
        # if would be possible to merge into the following chunk,
        # if the file in the following chunk were to be deleted.
        if chunk.size >= (file.size + HEADER_SIZE):
            if diamond:
                addr2 = chunk.body + file.size
            else:
                addr2 = chunk.next - file.size - HEADER_SIZE

            chunk1 = KissChunk(CHUNK_FREE, chunk.addr, chunk.prev, addr2)
            sav.seek(chunk1.addr.cram + 4)
            write_struct("<H", sav, chunk1.next.gb)

            chunk2 = KissChunk(CHUNK_FREE, addr2, chunk.addr, chunk.next)
            sav.seek(chunk2.addr.cram)
            write_struct(
                "<BBHH",
                sav,
                chunk2.type,
                chunk2.type ^ 0xFF,
                chunk2.prev.gb,
                chunk2.next.gb,
            )

            sav.seek(chunk2.next.adjusted().cram + 2)
            write_struct("<H", sav, chunk2.addr.gb)

            if diamond:
                chunk = chunk1
            else:
                chunk = chunk2
            assert chunk.size == file.size

        sav.seek(chunk.addr.cram)
        if diamond:
            write_struct("<BB", sav, CHUNK_INITIAL, CHUNK_INITIAL ^ 0xFF)
        else:
            write_struct("<BB", sav, CHUNK_REGULAR, CHUNK_REGULAR ^ 0xFF)
        sav.seek(chunk.body.cram)
        sav.write(data)

        sav.seek(meta.index.body.cram + (4 * index_loc))
        meta = write_struct("<HBB", sav, chunk.body.cram, file.cart_id, file.owner)


def move_command(parser, args):
    raise NotImplementedError()


def del_command(parser, args):
    with open_kiss(args, "rb+") as (meta, rom, sav):
        if rom is not None:
            raise ToolError("cannot delete file from ROM file")

        for i, entry in enumerate(read_index(sav, meta)):
            if entry.addr.cram == 0 or entry.cart_id == 0xFF:
                continue
            file = read_file_header(sav, seek=entry.addr)
            if (file.title == args.title) or (str(i) == args.title):
                break
        else:
            raise KeyError(args.title)

        # Set the chunk type to $46 (free)
        chunk = read_chunk_header(sav, seek=entry.addr - HEADER_SIZE)
        sav.seek(chunk.addr.cram)
        write_struct("<BB", sav, CHUNK_FREE, CHUNK_FREE ^ 0xFF)

        # Merge this chunk into previous, if previous chunk is free too.
        if chunk.addr.gb != 0xA002:
            prev = read_chunk_header(sav, seek=chunk.prev)
            if prev.type == CHUNK_FREE:
                chunk = KissChunk(CHUNK_FREE, prev.addr, prev.prev, chunk.next)
                sav.seek(chunk.addr.cram + 4)
                write_struct("<H", sav, chunk.next.gb)

        # Merge next chunk into this, if next chunk is free too.
        if chunk.next.gb != 0xC000:
            next = read_chunk_header(sav, seek=chunk.next)
            if next.type == CHUNK_FREE:
                chunk = KissChunk(CHUNK_FREE, chunk.addr, chunk.prev, next.next)
                sav.seek(chunk.addr.cram + 4)
                write_struct("<H", sav, chunk.next.gb)

        # Ensure next chunk points to this.
        # There is always a next chunk, because only special chunks are final.
        sav.seek(chunk.next.adjusted().cram + 2)
        write_struct("<H", sav, chunk.addr.gb)

        # Zero out the entry in the index.
        sav.seek(meta.index.body.cram + (4 * i))
        write_struct("<HBB", sav, 0, 0, 0)

        print(f"Reclaimed {file.size+HEADER_SIZE} bytes of space", file=sys.stderr)


def _columnify(table):
    table = [[str(x) for x in row] for row in table]
    widths = [
        max(_strwidth(x or "") for x in col) for col in itertools.zip_longest(*table)
    ]
    for row in table:
        print("  ".join(_ljust(x, w) for w, x in zip(widths, row[:-1])), end="  ")
        print(row[-1])


def _charwidth(ch: str) -> int:
    return {"F": 2, "W": 2}.get(unicodedata.east_asian_width(ch), 1)


def _strwidth(text: str) -> int:
    return sum(_charwidth(ch) for ch in text)


def _ljust(text: str, width: int) -> str:
    return text + (" " * (width - _strwidth(text)))


_chars = dict(
    enumerate(
        "\0abcdefghijklmno"
        "pqrstuvwxyz｢|｣¯\\"
        " !\"#$%&'()*+,-./"
        "0123456789:;<=>?"
        "@ABCDEFGHIJKLMNO"
        "PQRSTUVWXYZ[¥]^_"
        "をあいうえおかきくけこさしすせそ"
        "たちつてとなにぬねのはひふへほま"
        "みむめもやゆよらりるれろわんがぎ"
        "ぐげござじずぜぞだぢづでどばびぶ"
        "べぼぱぴぷぺぽぁぃぅぇぉゃゅょっ"
        "ヲアイウエオカキクケコサシスセソ"
        "タチツテトナニヌネノハヒフヘホマ"
        "ミムメモヤユヨラリルレロワンガギ"
        "グゲゴザジズゼゾダヂヅデドバビブ"
        "ベボパピプペポァィゥェォャュョッ"
    )
)

_katakana = {0: "\0"}
_katakana.update(
    enumerate(
        " !\"#$%&'()*+,-./0123456789:;<=>?"
        "@ABCDEFGHIJKLMNOPQRSTUVWXYZ[¥]^_"
        "\0abcdefghijklmnopqrstuvwxyz｢|｣¯\\",
        start=0x20,
    )
)
_hiragana = dict(_katakana)
_katakana.update(enumerate("ヲァィゥェォャュョッー", start=0xA6))
_katakana.update(
    enumerate("アイウエオカキクケコサシスセソタチツテトナニヌネノ", start=0xB1)
)
_katakana.update(enumerate("ハヒフヘホマミムメモヤユヨラリルレロワン", start=0xCA))
_hiragana.update(enumerate("をぁぃぅぇぉゃゅょっー", start=0xA6))
_hiragana.update(
    enumerate("あいうえおかきくけこさしすせそたちつてとなにぬねの", start=0xB1)
)
_hiragana.update(enumerate("はひふへほまみむめもやゆよらりるれろわん", start=0xCA))

_charmaps = {0x0E: _katakana, 0x0F: _hiragana}
_diacritics = {
    0xDE: dict(
        zip(
            "カキクケコサシスセソタチツテトハヒフヘホかきくけこさしすせそたちつてとはひふへほ",
            "ガギグゲゴザジズゼゾダヂヅデドバビブベボがぎぐげござじずぜぞだぢづでどばびぶべぼ",
        )
    ),
    0xDF: dict(
        zip(
            "ハヒフヘホはひふへほ",
            "パピプペポぱぴぷぺぽ",
        )
    ),
}


def _no_encode(text: str):
    raise NotImplementedError


def _decode_string(data: bytes):
    charmap = _katakana
    text = ""
    for byte in data:
        if byte in _charmaps:
            charmap = _charmaps[byte]
        elif byte in _diacritics:
            if text[-1:] not in _diacritics[byte]:
                raise UnicodeDecodeError("modifier without valid preceder")
            text = text[:-1] + _diacritics[byte][text[-1:]]
        else:
            if byte not in charmap:
                raise UnicodeDecodeError("invalid byte")
            text += charmap[byte]
    return text, len(text)


def _decode_chars(data: bytes):
    text = "".join(_chars[byte] for byte in data)
    return text, len(text)


def _codec_search(name):
    if name == "gbkiss_string":
        return codecs.CodecInfo(_no_encode, _decode_string, name="gbkiss_string")
    if name == "gbkiss_char":
        return codecs.CodecInfo(_no_encode, _decode_chars, name="gbkiss_char")


codecs.register(_codec_search)


if __name__ == "__main__":
    main()
