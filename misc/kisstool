#!/usr/bin/env python3

import argparse
import codecs
import collections
import contextlib
import itertools
import os.path
import struct
import unicodedata


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("-f", "--file", required=True)
    parser.add_argument("-s", "--save")

    sub = parser.add_subparsers(dest="command")

    help = sub.add_parser("help", help="Show help")
    info = sub.add_parser("info", help="Show user info from save file")
    ls = sub.add_parser("ls", help="List file entries in save file")
    mv = sub.add_parser("mv", help="Move file entry within save file")
    get = sub.add_parser("get", help="Extract local file from save file")
    add = sub.add_parser("add", help="Insert local file into save file")
    rm = sub.add_parser("rm", help="Delete file entry from save file")

    add.add_argument("path")
    get.add_argument("title")
    get.add_argument("-o", "--out")

    args = parser.parse_args()

    cmd = {
        "help": help_command,
        "info": info_command,
        "ls": ls_command,
        "add": add_command,
        "get": get_command,
        "mv": mv_command,
        "rm": rm_command,
    }[args.command or "help"]
    cmd(parser, args)


KissMeta = collections.namedtuple("KissMeta", ["cap", "bank", "addr"])
KissChunk = collections.namedtuple("KissChunk", ["type", "prev", "next"])


class KissError(Exception):
    pass


@contextlib.contextmanager
def open_sav(args, mode):
    rom_path = args.file
    sav_path = args.save
    if not sav_path:
        rom_base, ext = os.path.splitext(rom_path)
        sav_path = rom_base + ".sav"
    with open(rom_path, "rb") as f:
        f.seek(0x13)
        meta = KissMeta(*struct.unpack("<HBH", f.read(5)))
    with open(sav_path, mode) as f:
        yield meta, f


def gb2cram(bank, addr):
    """Convert addr in CRAM memory space to Game Boy space"""
    return (bank << 13) + (addr - 0xA000)


def cram2gb(addr):
    """Convert addr in Game Boy memory space to CRAM space"""
    return (addr >> 13), ((addr % 0x2000) + 0xA000)


def read_chunk_header(sav, address):
    sav.seek(address)
    ctype, inv_ctype, prevc, nextc = struct.unpack("<BBHH", sav.read(6))
    assert (ctype ^ inv_ctype) == 0xFF
    return KissChunk(ctype, prevc, nextc)


def help_command(parser, args):
    parser.print_help()


def info_command(parser, args):
    with open_sav(args, "rb") as (meta, sav):
        profile = read_chunk_header(sav, gb2cram(meta.bank, meta.addr))
        assert profile.type == 0x53
        assert (profile.next % 0x2000) == 0
        assert (meta.addr - profile.prev) == 486

        _ = sav.read(64)  # not sure what is here
        profile = sav.read(58)
        name = profile[0:10].decode("gbkiss_char").rstrip()
        number = profile[10:22].decode("gbkiss_char").rstrip()
        memo = [
            profile[22:34].decode("gbkiss_char").rstrip(),
            profile[34:46].decode("gbkiss_char").rstrip(),
            profile[46:58].decode("gbkiss_char").rstrip(),
        ]
        while memo and not memo[-1]:
            memo.pop()
        print(f"NAME: {name}")
        print(f"NUM:  {number}")
        print("MEMO: " + "\n      ".join(memo))


def ls_command(parser, args):
    with open_sav(args, "rb") as (meta, sav):
        profile = read_chunk_header(sav, gb2cram(meta.bank, meta.addr))
        assert profile.type == 0x53
        assert (profile.next % 0x2000) == 0
        assert (meta.addr - profile.prev) == 486

        index = read_chunk_header(sav, gb2cram(meta.bank, profile.prev))
        assert index.type == 0x53
        assert index.next == meta.addr

        entries = []
        for i in range(120):
            entries.append(struct.unpack("<HBB", sav.read(4)))

        table = [("N", "TITLE", "SIZE", "MARK", "OWNER", "ICON")]
        for i, entry in enumerate(entries):
            if not entry[0]:
                continue
            elif entry[1] != 0:
                table.append((i, "KISS MAIL", "n/a", "◎", "$01", "auto"))
                continue
            chunk = read_chunk_header(sav, entry[0] - 6)
            size, flags, reserved, header, owner = struct.unpack("<HBBBB", sav.read(6))
            if not flags & 0x10:
                icon_size = 0x00
                icon_kind = ""
            elif not flags & 0x08:
                icon_size = 0x60
                icon_kind = "1bpp"
            else:
                icon_size = 0xC0
                icon_kind = "2bpp"
            if not flags & 0x04:
                kind = "△"
            elif not flags & 0x02:
                kind = "○"
            else:
                kind = "◇"
            if not icon_size:
                if owner in (0x01, 0x81, 0x40, 0x41, 0x42, 0x43, 0x44, 0x45, 0xFF):
                    icon_kind = "auto"
                elif owner == 0x00:
                    icon_kind = "text"
            title = sav.read(header - icon_size - 1).decode("gbkiss_string")
            table.append((i, title, size, kind, "$%02x" % owner, icon_kind))

        _columnify(table)


def get_command(parser, args):
    with open_sav(args, "rb") as (meta, sav):
        profile = read_chunk_header(sav, gb2cram(meta.bank, meta.addr))
        assert profile.type == 0x53
        assert (profile.next % 0x2000) == 0
        assert (meta.addr - profile.prev) == 486

        index = read_chunk_header(sav, gb2cram(meta.bank, profile.prev))
        assert index.type == 0x53
        assert index.next == meta.addr

        entries = []
        for i in range(120):
            entries.append(struct.unpack("<HBB", sav.read(4)))

        for i, entry in enumerate(entries):
            if entry[1] or not entry[0]:
                continue
            chunk = read_chunk_header(sav, entry[0] - 6)
            start = sav.tell()
            size, flags, reserved, header, owner = struct.unpack("<HBBBB", sav.read(6))
            if not flags & 0x10:
                icon_size = 0x00
            elif not flags & 0x08:
                icon_size = 0x60
            else:
                icon_size = 0xC0
            title = sav.read(header - icon_size - 1).decode("gbkiss_string")
            if title == args.title:
                break
        else:
            raise KeyError(args.title)

        sav.seek(start)
        data = sav.read(size)
        out_path = args.out
        if out_path is None:
            out_path = title + ".gbk"
        with open(out_path, "wb") as out:
            out.write(data)
        print(f"Wrote {size} bytes to {out_path}")


def add_command(parser, args):
    raise NotImplementedError()


def mv_command(parser, args):
    raise NotImplementedError()


def rm_command(parser, args):
    raise NotImplementedError()


def _columnify(table):
    table = [[str(x) for x in row] for row in table]
    widths = [
        max(_strwidth(x or "") for x in col) for col in itertools.zip_longest(*table)
    ]
    for row in table:
        print("  ".join(_ljust(x, w) for w, x in zip(widths, row[:-1])), end="  ")
        print(row[-1])


def _charwidth(ch: str) -> int:
    return {"F": 2, "W": 2}.get(unicodedata.east_asian_width(ch), 1)


def _strwidth(text: str) -> int:
    return sum(_charwidth(ch) for ch in text)


def _ljust(text: str, width: int) -> str:
    return text + (" " * (width - _strwidth(text)))


_chars = {}
_katakana = {}
_hiragana = {}
_dakuten = {}
_handakuten = {}


def _load_chars(charmaps, mapping):
    for base, chars in mapping.items():
        for i, ch in enumerate(chars):
            for charmap in charmaps:
                charmap[base + i] = ch


_load_chars(
    [_chars, _katakana, _hiragana],
    {
        0x00: "\0",
        0x20: " !\"#$%&'()*+,-./",
        0x30: "0123456789",
        0x3A: ":;<=>?@",
        0x41: "ABCDEFGHIJKLMNOPQRSTUVWXYZ",
        0x5B: "[\\]^_`",
    },
)
_load_chars(
    [_chars],
    {
        0x01: "abcdefghijklmnopqrstuvwxyz",
    },
)
_load_chars(
    [_katakana, _hiragana],
    {
        0x61: "abcdefghijklmnopqrstuvwxyz",
        0x7B: "{|}",
    },
)
_load_chars(
    [_katakana],
    {
        0xA6: "ヲァィゥェォャュョッー",
        0xB1: "アイウエオカキクケコサシスセソタチツテトナニヌネノ",
        0xCA: "ハヒフヘホマミムメモヤユヨラリルレロワン",
    },
)
_load_chars(
    [_hiragana],
    {
        0xA6: "をぁぃぅぇぉゃゅょっー",
        0xB1: "あいうえおかきくけこさしすせそたちつてとなにぬねの",
        0xCA: "はひふへほまみむめもやゆよらりるれろわん",
    },
)
for src, dst in zip(
    "カキクケコサシスセソタチツテトハヒフヘホかきくけこさしすせそたちつてとはひふへほ",
    "ガギグゲゴザジズゼゾダヂヅデドバビブベボがぎぐげござじずぜぞだぢづでどばびぶべぼ",
):
    _dakuten[src] = dst
for src, dst in zip(
    "ハヒフヘホはひふへほ",
    "パピプペポぱぴぷぺぽ",
):
    _handakuten[src] = dst


def _no_encode(text: str):
    raise NotImplementedError


def _decode_string(data: bytes):
    charmap = _katakana
    text = ""
    for byte in data:
        if byte == 0x0E:
            charmap = _katakana
        elif byte == 0x0F:
            charmap = _hiragana
        elif byte == 0xDE:
            if text[-1:] not in _dakuten:
                raise UnicodeDecodeError("dakuten without preceding kana")
            text = text[:-1] + _dakuten[text[-1:]]
        elif byte == 0xDF:
            if text[-1:] not in _handakuten:
                raise UnicodeDecodeError("handakuten without preceding kana")
            text = text[:-1] + _handakuten[text[-1:]]
        elif byte not in charmap:
            raise UnicodeDecodeError("invalid byte")
        else:
            text += charmap[byte]
    return text, len(text)


def _decode_chars(data: bytes):
    text = ""
    for byte in data:
        text += _chars[byte]
    return text, len(text)


def _codec_search(name):
    if name == "gbkiss_string":
        return codecs.CodecInfo(_no_encode, _decode_string, name="gbkiss_string")
    if name == "gbkiss_char":
        return codecs.CodecInfo(_no_encode, _decode_chars, name="gbkiss_char")


codecs.register(_codec_search)


if __name__ == "__main__":
    main()
